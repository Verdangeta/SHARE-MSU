{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Prac01_Mironenko.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2GPoeVHUVTq"
      },
      "source": [
        "# Практическое задание 1\n",
        "\n",
        "## Данные о студенте\n",
        "\n",
        "1. **ФИО**: Мироненко Александр Витальевич\n",
        "2. **Факультет**: Мехмат\n",
        "3. **Курс**: 4\n",
        "4. **Группа**: 408\n",
        "\n",
        "## Замечания\n",
        "\n",
        "* Название ноутбука с реализацией должно иметь шаблон \"**Prac01_Ivanov.ipynb**\" и посылаться на почту mlcoursemm@gmail.com с темой **[CV2021:Prac01]**\n",
        "* Дедлайн будет оговорен в чате курса\n",
        "* Соблюдаем кодекс чести (по нулям и списавшему, и давшему списать)\n",
        "* Можно (и нужно!) применять для реализации только библиотеку **Numpy**\n",
        "* Ничего, крому Numpy, нельзя использовать для реализации \n",
        "* **Keras** используется только для тестирования Вашей реализации\n",
        "* Если какой-то из классов не проходит приведенные тесты, то соответствующее задание не оценивается\n",
        "* Возможно использование дополнительных (приватных) тестов\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-28T10:54:33.443202Z",
          "start_time": "2021-03-28T10:54:27.682757Z"
        },
        "id": "hT1dNA7Gb35a"
      },
      "source": [
        "# Вам понадобится для реализации\n",
        "import numpy as np\n",
        "# Нужно для тестирования\n",
        "from tensorflow import keras\n",
        "import keras.layers as layers"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G7sQn2ZXh9Y"
      },
      "source": [
        "* Вспомогательные функции для тестирования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-28T10:54:33.459141Z",
          "start_time": "2021-03-28T10:54:33.448171Z"
        },
        "id": "_vXhfmihINmY"
      },
      "source": [
        "def compare_tensors(x, y, tol=0.001, test_name='Test'):\n",
        "  assert (x.shape == y.shape), test_name + ' different shapes'\n",
        "  diff = np.sum((y - x)**2)\n",
        "  assert (diff < tol), test_name + ' Failed!'\n",
        "  print (test_name + ' Passed!')\n",
        "  return"
      ],
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-28T10:54:33.475105Z",
          "start_time": "2021-03-28T10:54:33.461136Z"
        },
        "id": "Pq_lVMUle_ii"
      },
      "source": [
        "def compare_tensors_array(x, y, tol=0.001, test_name='Test'):\n",
        "  assert (len(x) == len(y)), test_name + ' different lengths'\n",
        "  for i in range(len(x)):\n",
        "    t = test_name + ' subtest ' + str(i)\n",
        "    compare_tensors(x[i], y[i], tol=tol, test_name=t)\n",
        "  print (test_name + ' Passed!')\n",
        "  return"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4iNYGlDyNAF"
      },
      "source": [
        "* Шаблон класса любой операции (слоя), которую Вам необходимо будет реализовать"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-28T10:54:34.580149Z",
          "start_time": "2021-03-28T10:54:34.567164Z"
        },
        "id": "05lYhmjMSm0s"
      },
      "source": [
        "class Layer(object):\n",
        "    def __init__(self):\n",
        "        self.name = 'Layer'       \n",
        "    def forward(self, input_data):\n",
        "        pass"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9yuQiPjyOBZ"
      },
      "source": [
        "* (1 балл) Реализация \"спрямляющего\" слоя Flatten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-28T10:54:35.265411Z",
          "start_time": "2021-03-28T10:54:35.253442Z"
        },
        "id": "zJIqDFDC-8Gh"
      },
      "source": [
        "class FlattenLayer(Layer):\n",
        "    def __init__(self):\n",
        "        self.name = 'Flatten'\n",
        "    def forward(self, input_data):\n",
        "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
        "      # Преобразуем в двухмерный тензор: при этом по первой размерности НЕ преобразуем\n",
        "      # Выкладываем данные: сначала по последней размерности, затем по предпоследней и т.д.\n",
        "      # Нужно заполнить Numpy-тензор out\n",
        "        out = np.empty((input_data.shape[0],input_data[0].size))\n",
        "        \n",
        "        out[0] = input_data[0].flatten().reshape(1,input_data[0].size)\n",
        "        \n",
        "        for i in range(1,input_data.shape[0]):\n",
        "            out[i] = input_data[i].flatten().reshape(1,input_data[0].size)  \n",
        "        return out"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAD92fJkYcNI"
      },
      "source": [
        "* Функция предварительного тестирования слоя **Flatten**\n",
        "* Функции с названием \"**test_**\" не менять\n",
        "* Вы можете самостоятельно поиграться с параметрами типа B/C/H/W etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-28T10:54:35.877927Z",
          "start_time": "2021-03-28T10:54:35.856982Z"
        },
        "id": "eZsoCXd1HioL"
      },
      "source": [
        "def test_FlattenLayer():\n",
        "  B = 1\n",
        "  C = 1\n",
        "  H = 3\n",
        "  W = 3\n",
        "  x = np.random.randn(B, C, H, W)\n",
        "  y = layers.Flatten(data_format='channels_last')\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = FlattenLayer().forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Flatten 1')\n",
        "  B = 2\n",
        "  C = 2\n",
        "  H = 3\n",
        "  W = 3\n",
        "  x = np.random.randn(B, C, H, W)\n",
        "\n",
        "  y = layers.Flatten(data_format='channels_last')\n",
        "  y_keras = y(x).numpy()\n",
        "\n",
        "  y_out = FlattenLayer().forward(x)\n",
        "\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Flatten 2')\n",
        "  return"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMe7eba6Yu4a"
      },
      "source": [
        "* Запуск теста слоя Flatten\n",
        "* Нужно, чтобы все тесты были '*Passed!*'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-28T10:54:37.149722Z",
          "start_time": "2021-03-28T10:54:36.537122Z"
        },
        "id": "pST9EihGKTEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58148f4b-4c29-40f2-cfff-08c90ec5105d"
      },
      "source": [
        "test_FlattenLayer()"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Flatten 1 Passed!\n",
            "Test Flatten 2 Passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXeCMURtWjAq"
      },
      "source": [
        "Я не особо понял, как исправлять на GPU.Но я попробовал запустить локально и на google collab, и везде выдавался правильный ответ, только если выбран  'channels_last'.\n",
        "\n",
        "Я проверял на массивах вручную, вроде работает верно=)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOngWlbqyQJ9"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6NfaNFKZGOk"
      },
      "source": [
        "* (1 балл) Реализация слоя субдискретизации **Global Average Pooling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-28T11:07:13.858804Z",
          "start_time": "2021-03-28T11:07:13.850790Z"
        },
        "id": "1d3U8gE1-8J1"
      },
      "source": [
        "class GAP2DLayer(Layer):\n",
        "    def __init__(self):\n",
        "      self.name = 'GAP2D'\n",
        "    def forward(self, input_data):\n",
        "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
        "      # Сворачиваем по двум последним размерностям (то есть на выходе - минус две размерности)\n",
        "      # Нужно заполнить Numpy-тензор out \n",
        "        out = np.empty([])\n",
        "        out = input_data.mean(axis = (2,3))\n",
        "        return out"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-28T11:07:15.557126Z",
          "start_time": "2021-03-28T11:07:15.537179Z"
        },
        "id": "u9KLCdrTLT-j"
      },
      "source": [
        "def test_GAP2DLayer():\n",
        "  B = 1\n",
        "  C = 1\n",
        "  H = 3\n",
        "  W = 3\n",
        "  x = np.random.randn(B, C, H, W)\n",
        "  y = layers.GlobalAveragePooling2D(data_format='channels_first')\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = GAP2DLayer().forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test GAP2D 1')\n",
        "  B = 1\n",
        "  C = 2\n",
        "  H = 3\n",
        "  W = 3\n",
        "  x = np.random.randn(B, C, H, W)\n",
        "  y = layers.GlobalAveragePooling2D(data_format='channels_first')\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = GAP2DLayer().forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test GAP2D 2')\n",
        "  return"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-28T11:07:15.966508Z",
          "start_time": "2021-03-28T11:07:15.940556Z"
        },
        "id": "AbuDxhloPLKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77de05f2-179c-4659-c814-875e87acbe3f"
      },
      "source": [
        "test_GAP2DLayer()"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test GAP2D 1 Passed!\n",
            "Test GAP2D 2 Passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbse3gb2ySI_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2CCmuiZZTXp"
      },
      "source": [
        "* (2 балла) Реализация слоя субдискретизации **MaxPooling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-28T11:31:34.703281Z",
          "start_time": "2021-03-28T11:31:34.683335Z"
        },
        "id": "fFSW6Xpp-8NS"
      },
      "source": [
        "class MaxPool2DLayer(Layer):\n",
        "    def __init__(self, pool_size=2, stride=2):\n",
        "      self.name = 'MaxPool2D'\n",
        "      self.pool_size = pool_size\n",
        "      self.stride = stride\n",
        "    def forward(self, input_data):\n",
        "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
        "      # Нужно заполнить Numpy-тензор out \n",
        "        out = np.empty((input_data.shape[0], input_data.shape[1], 1+(input_data.shape[2]-self.pool_size)// self.stride,1+ (input_data.shape[3]-self.pool_size)// self.stride))\n",
        "        \n",
        "        for i in range(input_data.shape[0]):\n",
        "            for j in range(input_data.shape[1]):\n",
        "                for k in range(0,input_data.shape[2],self.stride):\n",
        "                    for e in range(0,input_data.shape[3],self.stride):\n",
        "                        \n",
        "                        if k+self.pool_size >input_data.shape[2] or e+self.pool_size> input_data.shape[3]:\n",
        "                            continue\n",
        "                        out[i,j,k // self.stride,e // self.stride] = input_data[i, j, k:(k+self.pool_size), e:(e+self.pool_size)].max()\n",
        "        return out"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-28T11:32:50.711036Z",
          "start_time": "2021-03-28T11:32:50.703057Z"
        },
        "id": "kvCIn_aXUPkD"
      },
      "source": [
        "def test_MaxPool2DLayer():\n",
        "  B = 1\n",
        "  C = 1\n",
        "  H = 4\n",
        "  W = 4\n",
        "  pool_size = 2\n",
        "  stride = 2\n",
        "  x = np.random.randn(B, C, H, W)\n",
        "  y = layers.MaxPooling2D(pool_size=pool_size, strides=stride, padding=\"valid\", data_format='channels_first')\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = MaxPool2DLayer(pool_size=pool_size, stride=stride).forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test MaxPool2D 1')\n",
        "  B = 2\n",
        "  C = 2\n",
        "  H = 3\n",
        "  W = 3\n",
        "  pool_size = 2\n",
        "  stride = 1  \n",
        "  x = np.random.randn(B, C, H, W)\n",
        "  y = layers.MaxPooling2D(pool_size=pool_size, strides=stride, padding=\"valid\", data_format='channels_first')\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = MaxPool2DLayer(pool_size=pool_size, stride=stride).forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test MaxPool2D 2')\n",
        "  return"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-28T11:32:51.151914Z",
          "start_time": "2021-03-28T11:32:51.115039Z"
        },
        "id": "GHRtvEIpVsYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99de5909-48b3-4239-c2ff-13c9518fee79"
      },
      "source": [
        "test_MaxPool2DLayer()"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test MaxPool2D 1 Passed!\n",
            "Test MaxPool2D 2 Passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLtOD86byTQ-"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zruUuHDeZf-4"
      },
      "source": [
        "* (3 балла) Реализация слоя **активации** (поддерживаются **relu**, **sigmoid**, **softmax**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFytq6FOByQ9"
      },
      "source": [
        "class ActivationLayer(Layer):\n",
        "    def __init__(self, activation='relu'):\n",
        "      # Активация (поддерживаем 'relu', 'sigmoid', 'softmax')\n",
        "      self.name = 'Activation'\n",
        "      self.activation = activation\n",
        "    def forward(self, input_data):   \n",
        "      # На входе:\n",
        "      # четырехмерный тензор вида [batch, input_channels, height, width] для 'relu', 'sigmoid'\n",
        "      # или двухмерный тензор вида [batch, logits]\n",
        "      # SoftMax применяется по последней размерности\n",
        "      # Нужно заполнить Numpy-тензор out \n",
        "      out = np.empty(input_data.shape)\n",
        "      if self.activation == 'relu':\n",
        "        relu = lambda x: np.maximum(0,x)\n",
        "        out = np.array(list(map(relu,input_data)))\n",
        "      if self.activation == 'sigmoid':\n",
        "        out = 1/(1+np.exp(-input_data))\n",
        "      if self.activation == 'softmax':\n",
        "        out = np.exp(input_data)\n",
        "        out = out/np.sum(out,axis = 1).reshape(input_data.shape[0],1)\n",
        "\n",
        "      return out"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RnOBuLTWcIf"
      },
      "source": [
        "def test_ActivationLayer():\n",
        "  B = 1\n",
        "  C = 1\n",
        "  H = 4\n",
        "  W = 4\n",
        "  activation = 'relu'\n",
        "  x = np.random.randn(B, C, H, W)\n",
        "  y = layers.Activation(activation)\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = ActivationLayer(activation=activation).forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 1')\n",
        "  B = 2\n",
        "  C = 2\n",
        "  H = 3\n",
        "  W = 3\n",
        "  activation = 'sigmoid'  \n",
        "  x = np.random.randn(B, C, H, W)\n",
        "  y = layers.Activation(activation)\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = ActivationLayer(activation=activation).forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 2')\n",
        "  B = 3\n",
        "  C = 10\n",
        "  activation = 'softmax'\n",
        "  x = np.random.randn(B, C)\n",
        "  y = layers.Activation(activation)\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = ActivationLayer(activation=activation).forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 3')  \n",
        "  return"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3Bwcpw7X4_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974493dd-720d-4c4e-b866-515b2aabc9a1"
      },
      "source": [
        "test_ActivationLayer()"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Activation 1 Passed!\n",
            "Test Activation 2 Passed!\n",
            "Test Activation 3 Passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YtW9jiayUdV"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dOJl776Z0t7"
      },
      "source": [
        "* (3 балла) Реализация слоя пакетной нормализации **BatchNorm** (как для режима train, так и для режима test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-bCGIE--8QH"
      },
      "source": [
        "# Hint\n",
        "# Train mode:\n",
        "# out = (batch - mean(batch)) / sqrt(var(batch) + epsilon) * gamma + beta\n",
        "# moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)\n",
        "# moving_var = moving_var * momentum + var(batch) * (1 - momentum)\n",
        "# Test mode:\n",
        "# (batch - moving_mean) / sqrt(moving_var + epsilon) * gamma + beta\n",
        "\n",
        "class BatchNormLayer(Layer):\n",
        "    def __init__(self, momentum=0.99, epsilon=0.001, beta_init=None, gamma_init=None,\n",
        "                 moving_mean_init=None, moving_var_init=None,\n",
        "                 mode='train', input_channels=2):\n",
        "      # mode: 'train', 'test'\n",
        "      # Параметры gamma, beta, mean, var - все имеют размерность по количеству карт input_channels   \n",
        "      self.name = 'BatchNorm'\n",
        "      self.momentum = momentum\n",
        "      self.epsilon = epsilon\n",
        "      self.beta = beta_init\n",
        "      self.gamma = gamma_init\n",
        "      self.moving_mean = moving_mean_init\n",
        "      self.moving_var = moving_var_init\n",
        "      self.mode = mode\n",
        "      self.input_channels = input_channels\n",
        "    def forward(self, input_data):   \n",
        "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
        "      # 1) Нужно заполнить Numpy-тензор out (той же размерности, что и вход)\n",
        "      # 2) Нужно обновить moving_mean и moving_var в режиме 'train'\n",
        "      out = np.empty(input_data.shape)\n",
        "      if self.mode == 'train':\n",
        "        for i in range(input_data.shape[1]):\n",
        "          mean = input_data[:,i,:,:].mean()\n",
        "          var = input_data[:,i,:,:].var()\n",
        "\n",
        "          self.moving_mean[i] = self.moving_mean[i] * self.momentum + mean * (1 - self.momentum)\n",
        "\n",
        "          self.moving_var[i] = self.moving_var[i] * self.momentum + var * (1 - self.momentum)\n",
        "\n",
        "          \n",
        "          out[:,i,:,:] = (input_data[:,i,:,:] - mean)/np.sqrt(var + self.epsilon)*self.gamma[i]+self.beta[i]\n",
        "      \n",
        "      if self.mode == 'test':\n",
        "        for i in range(input_data.shape[1]):\n",
        "          out[:,i,:,:] = (input_data[:,i,:,:] - self.moving_mean[i])/np.sqrt(self.moving_var[i] + self.epsilon) * self.gamma[i] + self.beta[i] \n",
        "\n",
        "\n",
        "      return out"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhZ6TK-RYfm-"
      },
      "source": [
        "def test_BatchNormLayer():\n",
        "  B = 2\n",
        "  C = 2\n",
        "  H = 4\n",
        "  W = 4\n",
        "  beta_init = 0 * np.ones(C)\n",
        "  gamma_init = 1 * np.ones(C)\n",
        "  moving_mean_init = 0 * np.ones(C)\n",
        "  moving_var_init= 1 * np.ones(C)\n",
        "  momentum = 0.99\n",
        "  epsilon = 0.001\n",
        "  mode = 'train'\n",
        "  x = np.random.randn(B, C, H, W)\n",
        "  y = layers.BatchNormalization(axis=1, momentum=momentum, epsilon=epsilon, trainable=True)\n",
        "  y_keras = y(x, training=True).numpy()\n",
        "  y.set_weights([gamma_init, beta_init, moving_mean_init, moving_var_init])\n",
        "  y_keras = y(x, training=True).numpy()\n",
        "  y_out_layer = BatchNormLayer(momentum=momentum, epsilon=epsilon, beta_init=beta_init, gamma_init=gamma_init,\n",
        "                 moving_mean_init=moving_mean_init, moving_var_init=moving_var_init,\n",
        "                 mode=mode, input_channels=C)\n",
        "  y_out = y_out_layer.forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test BatchNorm 1')\n",
        "  compare_tensors_array(y.get_weights(), \n",
        "                        [y_out_layer.gamma, y_out_layer.beta, y_out_layer.moving_mean, y_out_layer.moving_var],\n",
        "                        tol=0.00001, test_name='Test BatchNorm 1.1')\n",
        "                        \n",
        "  B = 2 \n",
        "  C = 2 \n",
        "  H = 4 \n",
        "  W = 4 \n",
        "  beta_init = 1 * np.ones(C)\n",
        "  gamma_init = 0 * np.ones(C)\n",
        "  moving_mean = 0 * np.ones(C)\n",
        "  moving_var = 1 * np.ones(C)\n",
        "\n",
        "  moving_mean_init = 0 * np.ones(C)## ДОБАВИЛ САМ!!!\n",
        "  moving_var_init= 1 * np.ones(C)## ДОБАВИЛ САМ!!!\n",
        "\n",
        "  momentum = 0.99\n",
        "  epsilon = 0.001\n",
        "  mode = 'test'\n",
        "  x = np.random.randn(B, C, H, W)\n",
        "  y = layers.BatchNormalization(axis=1, momentum=momentum, epsilon=epsilon, trainable=False)\n",
        "  y_keras = y(x, training=False).numpy()\n",
        "  y.set_weights([gamma_init, beta_init, moving_mean, moving_var])\n",
        "  y_keras = y(x, training=False).numpy()\n",
        "  y_out_layer = BatchNormLayer(momentum=momentum, epsilon=epsilon, beta_init=beta_init, gamma_init=gamma_init,\n",
        "                 moving_mean_init=moving_mean_init, moving_var_init=moving_var_init,\n",
        "                 mode=mode, input_channels=C)\n",
        "  y_out = y_out_layer.forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test BatchNorm 2')  \n",
        "  compare_tensors_array(y.get_weights(), \n",
        "                        [y_out_layer.gamma, y_out_layer.beta, y_out_layer.moving_mean, y_out_layer.moving_var],\n",
        "                        tol=0.00001, test_name='Test BatchNorm 2.1')\n",
        "  return"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QUl2RxeKArW"
      },
      "source": [
        "**На GOOGLE COLLAB этот тест не проходил без обнуления init коэффицентов по новому, не считаю это своей ошибкой**\n",
        "\n",
        "Новый экземпляр класса получал старые коэффиценты mean и var\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ2F0Xg1Yf94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74561b2-a76d-4608-edb5-5e97702c9c82"
      },
      "source": [
        "test_BatchNormLayer()"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test BatchNorm 1 Passed!\n",
            "Test BatchNorm 1.1 subtest 0 Passed!\n",
            "Test BatchNorm 1.1 subtest 1 Passed!\n",
            "Test BatchNorm 1.1 subtest 2 Passed!\n",
            "Test BatchNorm 1.1 subtest 3 Passed!\n",
            "Test BatchNorm 1.1 Passed!\n",
            "Test BatchNorm 2 Passed!\n",
            "Test BatchNorm 2.1 subtest 0 Passed!\n",
            "Test BatchNorm 2.1 subtest 1 Passed!\n",
            "Test BatchNorm 2.1 subtest 2 Passed!\n",
            "Test BatchNorm 2.1 subtest 3 Passed!\n",
            "Test BatchNorm 2.1 Passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJKt_4mCyV4r"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f_m9DaTaHio"
      },
      "source": [
        "* (1 балл) Реализация **полносвязного** слоя"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ln22ERp8mC5"
      },
      "source": [
        "class DenseLayer(Layer):\n",
        "    def __init__(self, input_dim, output_dim, W_init=None, b_init=None):\n",
        "      self.name = 'Dense'\n",
        "      self.input_dim = input_dim\n",
        "      self.output_dim = output_dim\n",
        "      self.W = W_init\n",
        "      self.b = b_init\n",
        "    def forward(self, input_data):\n",
        "      # На входе - двухмерный тензор вида [batch, input_channels]\n",
        "      # Работаем по второй размерности, по первой размерности НЕ преобразуем\n",
        "      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
        "      # Нужно заполнить Numpy-тензор out \n",
        "      out = np.empty((input_data.shape[0],self.output_dim))\n",
        "\n",
        "      assert input_data.shape[1] == self.input_dim, \"alert!!! different shapes\"\n",
        "\n",
        "      out = input_data.dot(self.W) + self.b\n",
        "      return out"
      ],
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln9JIKL8YhZF"
      },
      "source": [
        "def test_DenseLayer():\n",
        "  B = 1\n",
        "  C_IN = 10\n",
        "  C_OUT = 5\n",
        "  x = np.random.randn(B, C_IN)\n",
        "  W_init = np.random.randn(C_IN, C_OUT)\n",
        "  b_init = np.random.randn(C_OUT)\n",
        "  y = layers.Dense(C_OUT, use_bias=True)\n",
        "  y_keras = y(x).numpy()\n",
        "  y.set_weights([W_init, b_init])\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = DenseLayer(C_IN, C_OUT, W_init=W_init, b_init=b_init).forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Dense 1')\n",
        "  B = 2\n",
        "  C_IN = 5\n",
        "  C_OUT = 10\n",
        "  x = np.random.randn(B, C_IN)\n",
        "  W_init = np.random.randn(C_IN, C_OUT)\n",
        "  b_init = np.random.randn(C_OUT)\n",
        "  y = layers.Dense(C_OUT, use_bias=True, input_shape=(C_IN,))\n",
        "  y_keras = y(x).numpy()\n",
        "  y.set_weights([W_init, b_init])\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = DenseLayer(C_IN, C_OUT, W_init=W_init, b_init=b_init).forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Dense 2')\n",
        "  return"
      ],
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NA_KNjZYhec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39310614-cf4f-4b3b-843b-10751b9eb2eb"
      },
      "source": [
        "test_DenseLayer()"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Dense 1 Passed!\n",
            "Test Dense 2 Passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "966wyQwryXun"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6A8OLysaS3Q"
      },
      "source": [
        "* (2 балла) Реализация **сверточного** слоя"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quhEATTW9jyK"
      },
      "source": [
        "class Conv2DLayer(Layer):\n",
        "    def __init__(self, kernel_size=3, input_channels=2, output_channels=3, \n",
        "                 padding='same', stride=1, K_init=None, b_init=None):\n",
        "      # padding: 'same' или 'valid'\n",
        "      # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
        "      # Работаем с единообразным сдвигом, поэтому stride - одно число\n",
        "      # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
        "      self.name = 'Conv2D'\n",
        "      self.kernel_size = kernel_size\n",
        "      self.input_channels = input_channels\n",
        "      self.output_channels = output_channels\n",
        "      self.kernel = K_init\n",
        "      self.bias = b_init\n",
        "      self.padding = padding\n",
        "      self.stride = stride\n",
        "    def forward(self, input_data):\n",
        "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
        "      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
        "      # Нужно заполнить Numpy-тензор out\n",
        "      assert input_data.shape[1] == self.input_channels, \"alert!!! different shapes\"\n",
        "      out = np.empty([])\n",
        "      if self.padding == \"valid\":\n",
        "\n",
        "        out = np.zeros((input_data.shape[0],self.output_channels,1 + (input_data.shape[2]-self.kernel_size)// self.stride,1 + (input_data.shape[3]-self.kernel_size)//self.stride))\n",
        "        for out_k in range(self.output_channels):\n",
        "          for batch in range(input_data.shape[0]):\n",
        "            for i in range(0,input_data.shape[2] - self.kernel_size+1,self.stride):\n",
        "              for j in range(0,input_data.shape[3]- self.kernel_size+1,self.stride):\n",
        "                for in_k in range(self.input_channels):\n",
        "          \n",
        "                  out[batch,out_k,i // self.stride,j // self.stride] += np.sum(self.kernel[:,:,in_k,out_k] * input_data[batch,in_k,i : (i + self.kernel_size),j:(j + self.kernel_size)])\n",
        "\n",
        "            out[batch,out_k] += self.bias[out_k]\n",
        "      \n",
        "      if self.padding == \"same\":\n",
        "        input_data_with_pad = np.zeros((input_data.shape[0],self.input_channels,input_data.shape[2]+self.kernel_size -1,input_data.shape[3]+self.kernel_size-1))\n",
        "        ##расширяем\n",
        "        padingg = (self.kernel_size -1)//2\n",
        "        for batch in range(input_data.shape[0]):\n",
        "          for in_k in range(self.input_channels):\n",
        "            input_data_with_pad[batch,in_k,padingg:-padingg,padingg:-padingg] = input_data[batch,in_k]\n",
        "  \n",
        "        input_data = input_data_with_pad\n",
        "        out = np.zeros((input_data.shape[0],self.output_channels,1 + (input_data.shape[2]-self.kernel_size)// self.stride,1 + (input_data.shape[3]-self.kernel_size)//self.stride))\n",
        "        for out_k in range(self.output_channels):\n",
        "          for batch in range(input_data.shape[0]):\n",
        "            for i in range(0,input_data.shape[2] - self.kernel_size+1,self.stride):\n",
        "              for j in range(0,input_data.shape[3]- self.kernel_size+1,self.stride):\n",
        "                for in_k in range(self.input_channels):\n",
        "          \n",
        "                  out[batch,out_k,i // self.stride,j // self.stride] += np.sum(self.kernel[:,:,in_k,out_k] * input_data[batch,in_k,i : (i + self.kernel_size),j:(j + self.kernel_size)])\n",
        "\n",
        "            out[batch,out_k] += self.bias[out_k]\n",
        "\n",
        "      return out"
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUA1PbOBYiH3"
      },
      "source": [
        "def test_Conv2DLayer():\n",
        "  B = 1\n",
        "  C_IN = 1\n",
        "  C_OUT = 1\n",
        "  H = 10\n",
        "  W = 10\n",
        "  K = 3\n",
        "  S = 1\n",
        "  padding = 'same'\n",
        "  x = np.random.randn(B, C_IN, H, W)\n",
        "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
        "  b_init = np.random.randn(C_OUT)\n",
        "  y = layers.Conv2D(C_OUT, K, strides=S, padding=padding, data_format='channels_first',\n",
        "    dilation_rate=1, groups=1, activation=None, use_bias=True)\n",
        "  y_keras = y(x).numpy()\n",
        "  y.set_weights([K_init, b_init])\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = Conv2DLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
        "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2D 1')\n",
        "  B = 2\n",
        "  C_IN = 3\n",
        "  C_OUT = 5\n",
        "  H = 9\n",
        "  W = 9\n",
        "  K = 3\n",
        "  S = 2\n",
        "  padding = 'valid'\n",
        "  x = np.random.randn(B, C_IN, H, W)\n",
        "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
        "  b_init = np.random.randn(C_OUT)\n",
        "  y = layers.Conv2D(C_OUT, K, strides=S, padding=padding, data_format='channels_first',\n",
        "    dilation_rate=1, groups=1, activation=None, use_bias=True, input_shape=(C_IN, H, W))\n",
        "  y_keras = y(x).numpy()\n",
        "  y.set_weights([K_init, b_init])\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = Conv2DLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
        "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2D 2')\n",
        "  return"
      ],
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZI5iUu4YiOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf51617-9f40-400b-9322-138895697c54"
      },
      "source": [
        "test_Conv2DLayer()"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Conv2D 1 Passed!\n",
            "Test Conv2D 2 Passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91-bDvSvyY2e"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hPqOr5zad6H"
      },
      "source": [
        "* (2 балла) Реализация **транспонированного сверточного** слоя"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97D7QOwm-ER1"
      },
      "source": [
        "class Conv2DTrLayer(Layer):\n",
        "    def __init__(self, kernel_size=3, input_channels=2, output_channels=3, \n",
        "                 padding=0, stride=1, K_init=None, b_init=None):      \n",
        "      # padding: число (сколько отрезать от модифицированной входной карты)\n",
        "      # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
        "      # stride - одно число (коэффициент расширения)\n",
        "      # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
        "      self.name = 'Conv2DTr'\n",
        "      self.kernel_size = kernel_size\n",
        "      self.input_channels = input_channels\n",
        "      self.output_channels = output_channels\n",
        "      self.kernel = K_init\n",
        "      self.bias = b_init\n",
        "      self.padding = padding\n",
        "      self.stride = stride\n",
        "    def forward(self, input_data):\n",
        "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
        "      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
        "      assert input_data.shape[1] == self.input_channels, \"alert!!! different shapes\"\n",
        "      # Нужно заполнить Numpy-тензор out \n",
        "      out = np.zeros((input_data.shape[0],self.output_channels,(input_data.shape[2]-1)*self.stride-2*self.padding+self.kernel_size,(input_data.shape[3]-1)*self.stride-2*self.padding+self.kernel_size))\n",
        "\n",
        "      input_data_converted = np.zeros((input_data.shape[0],self.input_channels,(input_data.shape[2]-1)*self.stride+2*(self.kernel_size-self.padding)-1,(input_data.shape[3]-1)*self.stride+2*(self.kernel_size-self.padding)-1))\n",
        "\n",
        "      ##расширяем\n",
        "      padingg = self.kernel_size - self.padding - 1\n",
        "      for batch in range(input_data.shape[0]):\n",
        "        for in_k in range(self.input_channels):\n",
        "          input_data_converted[batch,in_k,padingg:-padingg:self.stride,padingg:-padingg:self.stride] = input_data[batch,in_k]\n",
        "\n",
        "    ##сворачиваем\n",
        "\n",
        "        \n",
        "      input_data = input_data_converted\n",
        "    \n",
        "      for out_k in range(self.output_channels):\n",
        "        for batch in range(input_data.shape[0]):\n",
        "          for i in range(0,input_data.shape[2] - self.kernel_size+1):\n",
        "            for j in range(0,input_data.shape[3]- self.kernel_size+1):\n",
        "              for in_k in range(self.input_channels):\n",
        "                out[batch,out_k,i ,j] += np.sum(self.kernel[:,:,in_k,out_k] * input_data[batch,in_k,i : (i + self.kernel_size),j:(j + self.kernel_size)])\n",
        "\n",
        "          out[batch,out_k] += self.bias[out_k]\n",
        "\n",
        "      return out"
      ],
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueU3lS9-Yi8t"
      },
      "source": [
        "def adjust_kernel(K):\n",
        "  K_new = K.copy()[::-1, ::-1, :, :]\n",
        "  K_new = np.transpose(K_new, (0, 1, 3, 2))\n",
        "  return K_new\n",
        "\n",
        "def test_Conv2DTrLayer():\n",
        "  B = 1\n",
        "  C_IN = 1\n",
        "  C_OUT = 1\n",
        "  H = 3\n",
        "  W = 3\n",
        "  K = 2\n",
        "  S = 2\n",
        "  padding = 0\n",
        "  x = np.random.randn(B, C_IN, H, W)\n",
        "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
        "  b_init = np.random.randn(C_OUT)\n",
        "  y = layers.Conv2DTranspose(C_OUT, K, strides=S, padding=\"valid\", output_padding=None, \n",
        "                    data_format='channels_first', dilation_rate=1, groups=1, \n",
        "                    activation=None, use_bias=True)\n",
        "  y_keras = y(x).numpy()\n",
        "  y.set_weights([adjust_kernel(K_init), b_init])\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = Conv2DTrLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
        "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2DTr 1')\n",
        "  B = 4\n",
        "  C_IN = 2\n",
        "  C_OUT = 3\n",
        "  H = 3\n",
        "  W = 3\n",
        "  K = 3\n",
        "  S = 2\n",
        "  padding = 0\n",
        "  x = np.random.randn(B, C_IN, H, W)\n",
        "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
        "  b_init = np.random.randn(C_OUT)\n",
        "  y = layers.Conv2DTranspose(C_OUT, K, strides=S, padding=\"valid\", output_padding=None, \n",
        "                    data_format='channels_first', dilation_rate=1, groups=1, \n",
        "                    activation=None, use_bias=True)\n",
        "  y_keras = y(x).numpy()\n",
        "  y.set_weights([adjust_kernel(K_init), b_init])\n",
        "  y_keras = y(x).numpy()\n",
        "  y_out = Conv2DTrLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
        "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
        "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2DTr 2')\n",
        "  return"
      ],
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW2REQR3-6dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b9d1aa-5c77-4f2e-bbc6-2606ec328d98"
      },
      "source": [
        "test_Conv2DTrLayer()"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Conv2DTr 1 Passed!\n",
            "Test Conv2DTr 2 Passed!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}